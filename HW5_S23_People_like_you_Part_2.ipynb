{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adm-2k/DataPPF/blob/main/HW5_S23_People_like_you_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGEmAD3FO5FV"
      },
      "source": [
        "# Homework 5  \n",
        "# \"People like you...\" (part 2)\n",
        "<b>ASSIGNED: 10 April 2023.</b>   \n",
        "<b>DUE: 25 April 2023 at 11:59 PM EST</b>\n",
        "\n",
        "\n",
        "Be sure to rename this notebook so it includes your name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L00BAtSrO5FW"
      },
      "source": [
        "#### Goal:\n",
        "\n",
        "Building on homework 4, in this (final! short!) homework we're going to do the following:\n",
        "\n",
        "1. Perform K-means to group individuals;\n",
        "2. Speculate on the significance of one grouping created in this way;\n",
        "3. Destroy privacy through de-anonymizing attacks.\n",
        "\n",
        "The homework should take you about <b>2.5 hours</b> to do. Special care has been taken to give you detailed examples. You only need adapt the example for the question asked. If you need help, please ask for help early!\n",
        "\n",
        "\n",
        "## Instructions\n",
        "* This assignment is to be done <b>on your own</b>, but you can talk about the assignment with your classmates if you get stuck. (Be sure to list the students you spoke with about this assignment in the space provided below.)\n",
        "* Feel free to also use [stackoverflow](https://stackoverflow.com/) but please provide citation and link to the specific answer if you do this.\n",
        "* You may also visit Graders during office hours or message them on Slack with questions.\n",
        "* <b>Only include relevant information in your output.</b> We should be able to see your answer clearly.\n",
        "* <b>Save pdf in Landscape</b> and check that all of your code is shown in the submission.\n",
        "* When submitting in Gradescope, be sure to <b>select the pages that corresponds to the code/output of the respective question</b>.\n",
        "\n",
        "\n",
        "### List any students you talked with about this assignment here:\n",
        "1. [person 1]\n",
        "2. [person 2]\n",
        "3. etc.\n",
        "\n",
        "\n",
        "\n",
        "## Homework Problems\n",
        "\n",
        "### Question 0: Stationkeeping Work [0 points]\n",
        "First, let's load libraries and the data from homework 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrYU7ITHO5FX"
      },
      "source": [
        "# loading libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as axes\n",
        "from sklearn.cluster import KMeans\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lgUv9baO5FX"
      },
      "source": [
        "# load data again / you will need to be connected to the internet to get data\n",
        "features = ['age','workclass', 'fnlwgt', 'education', 'education.num', 'marital.status','occupation', 'relationship','race','sex','capital.gain','capital.loss', 'hours.per.week', 'native.country','income']\n",
        "data=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', sep=',', header=None, na_values=\"?\", names=features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGVi-NifO5FY"
      },
      "source": [
        "# convert categorical data into numerical data\n",
        "def preprocess_features(dframe):\n",
        "    for column in dframe:\n",
        "        enc = LabelEncoder()\n",
        "        if(column not in ['age','education.num','fnlwgt','capital.gain','capital.loss','hours.per.week']):\n",
        "            dframe[column] = enc.fit_transform(dframe[column])\n",
        "    return dframe\n",
        "\n",
        "people = preprocess_features(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP2kHnWDO5FY"
      },
      "source": [
        "Importing the data points from our previous PCA analysis in homework 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRp2Dy6vO5FY"
      },
      "source": [
        "# get PCA results from previous homework via pickle file \"pca_coordinates.p\")\n",
        "from urllib.request import urlopen\n",
        "pca_coordinates = pickle.load(urlopen('http://www.columbia.edu/~chw2/Courses/PPF/Homeworks/2021/Homework5/pca_coordinates.p'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qarIbWTSO5FZ"
      },
      "source": [
        "len(pca_coordinates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX2jSz_SO5FZ"
      },
      "source": [
        "Now we again have a dataframe `people` that has 15 data points for 32,561 people (just like in the previous homework). We also have the PCA results for the last 1500 people from our previous homework in the list `pca_coordinates`. Note that the order of the PCA coordinates is also the order of the last 1500 people in `people`. Plotting our PCA results, we have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ink_z-DO5FZ"
      },
      "source": [
        "# Plot PCA results from last homework for\n",
        "X = []\n",
        "Y = []\n",
        "for person in pca_coordinates:\n",
        "    X.append(person[0])\n",
        "    Y.append(person[1])\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.title('PCA for last 1500 people', fontsize=15)\n",
        "plt.xlabel('PC 1', fontsize=10)\n",
        "plt.ylabel('PC 2', fontsize=10)\n",
        "plt.scatter(X,Y, alpha = .4, s = 40.)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVhHyCBtO5Fa"
      },
      "source": [
        "Also, in case you were curious, here's an image of PCA results performed on the entire dataset `people`, with the datapoint opacity (i.e., alpha) set very low so we can easily see how the data points are distributed.\n",
        "<img src=\"pca_all.png\">\n",
        "This gives us a hutch about both how many clusters we might want to look for as well as where these clusters might be located. We're just going to use the last 1500 people for our analysis in question 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAWSkZ2FO5Fa"
      },
      "source": [
        "### question 1 [20 points]  | clustering people\n",
        "Now we're going to use K-means in an attempt to cluster the people in our dataset `pca_coordinates` without explicitly defining what these clusters will be at the outset (i.e., we're doing unsupervised learning).\n",
        "\n",
        "ASIDE: If our discussion of K-means in lab 10a left you scratching your head, a helpful tutorial on K-means with python code here can be found here: https://mubaris.com/posts/kmeans-clustering/ . After picking the number of cluster center locations, K-means basically repeats the following two steps over and over: (1) reassign points according to which cluster center they are closest to and (2) readjusts the cluster center based on the mean distance of the data points in each cluster. The K-means procedure is completed once the cluster means and labels stop changing after number of iterations.\n",
        "\n",
        "#### To see how this is implemented in scikit learn, consider the following example. Let's take `X_example` data from the two columns \"age\" and \"hours worked\" in `people` and perform K-means on it.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb8h9NZ1O5Ff"
      },
      "source": [
        "# Gather X_example data from people dataframe\n",
        "# You won't need to use this cell for question 1 as we already have that data in `pca_coordinates` list\n",
        "\n",
        "# this takes the columns \"sex\" and \"marital.status\" and\n",
        "# combines them into a list of paired values that scikit-learn expects\n",
        "X_example = list(zip(people[\"age\"][0:500].values, people[\"hours.per.week\"][0:500].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7uhhnSrO5Ff"
      },
      "source": [
        "# Perform K_means on X_example\n",
        "\n",
        "# define number of clusters\n",
        "K = 2 # change K to whatever number of clusters you want\n",
        "kmeans_model = KMeans(n_clusters=K, n_init='auto')\n",
        "\n",
        "# perform K-means on X_example data\n",
        "kmeans = kmeans_model.fit(X_example)\n",
        "\n",
        "# Get cluster labels for each data point in X_example\n",
        "# where each cluster is denoted by a number. For six\n",
        "# clusters, the cluster labels = [0, 1, 2, 3, 4, 5].\n",
        "labels = kmeans.predict(X_example)\n",
        "\n",
        "# Get cluster center positions for each cluster.\n",
        "# This will just be the x,y coordinates for X_example.\n",
        "centers = kmeans.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV6roTWSO5Fg"
      },
      "source": [
        "We can plot X_example data and the cluster centroids as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJOteMhtO5Fg"
      },
      "source": [
        "print(centers) # will be pairs of x,y coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm6cfj5MO5Fg"
      },
      "source": [
        "We can plot the centers of the clusters (denoted by stars) and the X_example data color-coded by cluster like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5jTppHf9O5Fg"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.title('K-means on 500 people for age v hours worked', fontsize=15)\n",
        "plt.xlabel('age', fontsize=10)\n",
        "plt.ylabel('hours worked', fontsize=10)\n",
        "\n",
        "## THIS CODE IS USED TO PRODUCE \"INDEX LABELS\"\n",
        "## uncomment the \"#\" below to make an index label for each data point\n",
        "# ax = plt.subplot(111) #used to make indices\n",
        "# for text in range(0, len(X_example)):\n",
        "#    ax.annotate(text, xy=(X_example[text]), xycoords='data', xytext=(-30, -30), textcoords='offset points')\n",
        "\n",
        "# plot data\n",
        "plt.scatter([x[0] for x in X_example], [y[1] for y in X_example], c=labels, alpha = 0.6)\n",
        "plt.scatter([c_x[0] for c_x in centers], [c_y[1] for c_y in centers], marker='*', c='#050505', s=500)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xf8dG_fO5Fh"
      },
      "source": [
        "What are we to make of this? It's not obvious what two clusters we would expect using the \"age\" and \"hours worked per week\" data for 500 people. Since we picked 2 clusters, k-means effectively clustered our data into two halves. But you can easily change the number of clusters `K` and rerun k-means to see what different clusters you get. The stars, as already mentioned, denote the location of the centers of the clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2XVZZ6qO5Fh"
      },
      "source": [
        "#### Your turn!\n",
        "\n",
        "#### 1. Using the example above as a guide, perform K-means on our `pca_coordinates` data. (Hint: you'll use the list  `pca_coordinates` in place of `X_example` list above.)\n",
        "1a. Pick how many clusters `K` to use by examining plots \"PCA for last 1500 people\" and the \"2 component PCA for Similarity\" plots above. (Going off the PCA plots above, likely anywhere between 5 and 8 clusters might give good clusters.)\n",
        "\n",
        "#### 2. Graph the K-means clusters using the example code above. Uncomment the code that annotates the datapoints with their corresponding indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWOdqyNhO5Fi"
      },
      "source": [
        "# 1. WRITE K-MEANS CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. WRITE GRAPHING CODE HERE\n"
      ],
      "metadata": {
        "id": "sBgT2FGtqoZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn1kztQxO5Fi"
      },
      "source": [
        "## question 2 [30 points] | Writing fictions with data\n",
        "You've performed K-means on a PCA plot of the last 1500 people. Now it's time to use this data to make claims about the world.\n",
        "\n",
        "Imagine you're working in an advertising firm. Pick one cluster and examine what all the people around cluster have in common. They probably won't share just one attribute, but several similar features. Note which cluster you're looking at and *produce a story* about what life is like for these people. Be creative and don't be afraid to make inferences that are not contained by the data, as long as the data doesn't contradict your story.  Are they old? Young? How much do they work? Men? Women? Married? *Use evidence from the data to support your story.* [max 250 words, min 150 words]\n",
        "\n",
        "If you used the example code above, the coordinates of the cluster centers are stored in the list `centers`. To figure out what data points (i.e., people) are around a cluster, uncomment and use the code for \"INDEX LABELS\" above. This will attach a label to each data point. Once you have labels, you can zoom in on the section around the cluster to more easily read the index labels.\n",
        "\n",
        "Because we took the last 1500 people to produce our PCA coordinates and because our data set has 32561 people (with each row being one person), datapoint/person \"1\" will be the 31061st row in our dataframe `people`. Likewise datapoint/person \"2\" will be the 31062nd person, etc. The datapoint/person \"1500\" will be the last row in the data set. You can use the usual panda tricks on the dataframe `people` to see what these people have in common, and you can use this to infer/imagine what the cluster of people represents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGekZFaVO5Fi"
      },
      "source": [
        "Provide your story of the people in the cluster your choosing below:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code to get raw data associated with each person in a cluster\n",
        "adult = pd.read_csv('https://raw.githubusercontent.com/data-ppf/data-ppf.github.io/main/dat/adult.csv')\n",
        "from pandas import DataFrame\n",
        "my_people_indexes = [] # ENTER CODE HERE: CHOOSE SOME INDICIES IN A CLUSTER TO PUT IN THIS LIST\n",
        "\n",
        "for i in range(0, len(my_people_indexes)):\n",
        "  my_people_indexes[i] = my_people_indexes[i] + 31060\n",
        "\n",
        "my_people = adult.iloc[my_people_indexes, :]\n",
        "\n",
        "my_people"
      ],
      "metadata": {
        "id": "FcWnSOIGCwwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtj6vt93O5Fj"
      },
      "source": [
        "Put your story here...\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd85HkGfoBa1"
      },
      "source": [
        "## Question 3: Undermining privacy [40 points]\n",
        "\n",
        "In this section, you're going to undertake something like the deanonymizing process we undertook during lab, but with your old friend the adult data set, now with (fake) personal identification--fake Social security numbers, etc. And then you'll do some work to make the data set less prone to abuse\n",
        "\n",
        "Let's load the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8rAq5F7O5Fj"
      },
      "source": [
        "# getting the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "adult = pd.read_csv('https://raw.githubusercontent.com/data-ppf/data-ppf.github.io/main/dat/adult.csv')\n",
        "adult_pii = pd.read_csv('https://raw.githubusercontent.com/data-ppf/data-ppf.github.io/main/dat/adult_pii.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5JsHDe6rXWA"
      },
      "source": [
        "adult.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsNvrjSYrZZn"
      },
      "source": [
        "adult_pii.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F23fqQCEpVB-"
      },
      "source": [
        "Our goal is to deanonymize information in the adult data set by linking it to the highly private information in `adult_pii`.\n",
        "\n",
        "You task reidentify 4 people. That is, show which rows the names in the `adult` data set correspond to 4 people.\n",
        "\n",
        "HINT 1: Use techniques from the lab to help you. In the lab, we used `merge` on two large datasets; you can use merge with a single line of code using the names of the dataframes.\n",
        "\n",
        "HINT 2: Which columns are shared between both dataframes? Pandas `merge` lets you join on multiple columns if you pass a list into the `on` parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4BDLLCOuGUP"
      },
      "source": [
        "# ENTER CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EON9K-MF73OJ"
      },
      "source": [
        "# steps toward making a set k-anonymous\n",
        "\n",
        "\n",
        "Now you need to generalize your data.\n",
        "\n",
        "Age is very granular. Let's make it much less so.\n",
        "\n",
        "Write a function that converts the age of anyone greater than or equal to 50 to \"Ok, boomer\" and that age of anyone younger than 50 to \"Avocado Toast\".\n",
        "\n",
        "Use \"map\" to apply your function to every value in the age column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hezQmPSBj2Qv"
      },
      "source": [
        "def age_generalization(age):\n",
        "    if ## insert your code\n",
        "        return ###\n",
        "    else:\n",
        "        return ####\n",
        "\n",
        "#then apply this function to every row using the map function--a very powerful tool\n",
        "\n",
        "data.age = data.age.map(age_generalization)\n",
        "display(data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}